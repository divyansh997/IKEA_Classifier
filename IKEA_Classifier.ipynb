{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This is my directory structure:\n",
    "data/\n",
    "    train/\n",
    "        chairs/\n",
    "            1.jpg\n",
    "            2.jpg\n",
    "            ...\n",
    "        desks/\n",
    "            1.jpg\n",
    "            2.jpg\n",
    "            ...\n",
    "        ...\n",
    "    validate/\n",
    "        chairs/\n",
    "            1.jpg\n",
    "            2.jpg\n",
    "            ...\n",
    "        desks/\n",
    "            1.jpg\n",
    "            2.jpg\n",
    "            ...\n",
    "        ...\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing dependencies: keras, sklearn.metrics, numpy, pandas and matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining necessary parameters for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 250 \n",
    "image_height = 250\n",
    "\n",
    "# directories set as defined in cell 1\n",
    "\n",
    "training_directory = 'data/train'\n",
    "validation_directory = 'data/validate'\n",
    "testing_directory = 'data/test'\n",
    "\n",
    "# number of training images vary for each class. number of validation and testing images = 50 for each class\n",
    "# Number of Epochs was chosen randomly:\n",
    "# 40 would be sufficient since we have a small dataset\n",
    "# batch size = 16 since we have a small dataset\n",
    "number_training_imgs = 1038\n",
    "number_validation_imgs = 200\n",
    "epochs = 40\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, image_width, image_height)\n",
    "else:\n",
    "    input_shape = (image_width, image_height, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the CNN model: I use a sequential model having three convolution layers with ReLU activation followed by max-pooling layers. These layers are followed by two fully connected layers having ReLU and softmax activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_82 (Conv2D)           (None, 248, 248, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 248, 248, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_82 (MaxPooling (None, 124, 124, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 122, 122, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 122, 122, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_83 (MaxPooling (None, 61, 61, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 59, 59, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 59, 59, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_84 (MaxPooling (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 53824)             0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 64)                3444800   \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 3,473,700\n",
      "Trainable params: 3,473,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "classifier.add(Activation('relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "classifier.add(Conv2D(32, (3, 3)))\n",
    "classifier.add(Activation('relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "classifier.add(Conv2D(64, (3, 3)))\n",
    "classifier.add(Activation('relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# the model so far outputs 3D feature maps (height, width, features)\n",
    "\n",
    "classifier.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "classifier.add(Dense(64))\n",
    "classifier.add(Activation('relu'))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(4))\n",
    "classifier.add(Activation('softmax'))\n",
    "\n",
    "classifier.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(classifier.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used data-augmentation since I had a few training examples. This helps prevent overfitting since the model never sees the exact same image twice. I used keras.preprocessing.image.ImageDataGenerator class to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation configuration used for training\n",
    "\n",
    "trainingDataGenerator = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Augmentation configuration used for validating and testing: only rescaling\n",
    "\n",
    "validationDataGenerator = ImageDataGenerator(rescale=1. / 255)\n",
    "testDataGenerator = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1038 images belonging to 4 classes.\n",
      "Found 200 images belonging to 4 classes.\n",
      "Epoch 1/40\n",
      "64/64 [==============================] - 43s 672ms/step - loss: 1.2121 - acc: 0.4492 - val_loss: 0.8314 - val_acc: 0.7760\n",
      "Epoch 2/40\n",
      "64/64 [==============================] - 42s 664ms/step - loss: 0.8833 - acc: 0.6663 - val_loss: 0.7960 - val_acc: 0.8315\n",
      "Epoch 3/40\n",
      "64/64 [==============================] - 44s 691ms/step - loss: 0.8068 - acc: 0.7164 - val_loss: 0.5400 - val_acc: 0.8967\n",
      "Epoch 4/40\n",
      "64/64 [==============================] - 46s 714ms/step - loss: 0.6722 - acc: 0.7688 - val_loss: 0.9413 - val_acc: 0.7554\n",
      "Epoch 5/40\n",
      "64/64 [==============================] - 46s 716ms/step - loss: 0.6429 - acc: 0.7633 - val_loss: 0.4708 - val_acc: 0.8967\n",
      "Epoch 6/40\n",
      "64/64 [==============================] - 48s 754ms/step - loss: 0.5564 - acc: 0.8051 - val_loss: 0.4005 - val_acc: 0.9022\n",
      "Epoch 7/40\n",
      "64/64 [==============================] - 50s 784ms/step - loss: 0.6970 - acc: 0.7398 - val_loss: 0.5568 - val_acc: 0.8370\n",
      "Epoch 8/40\n",
      "64/64 [==============================] - 53s 831ms/step - loss: 0.5662 - acc: 0.8012 - val_loss: 0.3962 - val_acc: 0.8696\n",
      "Epoch 9/40\n",
      "64/64 [==============================] - 51s 801ms/step - loss: 0.4815 - acc: 0.8121 - val_loss: 0.4767 - val_acc: 0.8587\n",
      "Epoch 10/40\n",
      "64/64 [==============================] - 52s 818ms/step - loss: 0.4664 - acc: 0.8393 - val_loss: 0.5239 - val_acc: 0.8533\n",
      "Epoch 11/40\n",
      "64/64 [==============================] - 54s 847ms/step - loss: 0.4645 - acc: 0.8344 - val_loss: 0.3407 - val_acc: 0.9022\n",
      "Epoch 12/40\n",
      "64/64 [==============================] - 51s 799ms/step - loss: 0.4053 - acc: 0.8563 - val_loss: 0.5541 - val_acc: 0.8478\n",
      "Epoch 13/40\n",
      "64/64 [==============================] - 54s 838ms/step - loss: 0.4083 - acc: 0.8525 - val_loss: 0.4816 - val_acc: 0.8533\n",
      "Epoch 14/40\n",
      "64/64 [==============================] - 56s 875ms/step - loss: 0.4294 - acc: 0.8482 - val_loss: 0.4721 - val_acc: 0.8698\n",
      "Epoch 15/40\n",
      "64/64 [==============================] - 52s 819ms/step - loss: 0.4146 - acc: 0.8447 - val_loss: 0.4870 - val_acc: 0.8587\n",
      "Epoch 16/40\n",
      "64/64 [==============================] - 47s 742ms/step - loss: 0.3292 - acc: 0.8884 - val_loss: 0.3673 - val_acc: 0.8859\n",
      "Epoch 17/40\n",
      "64/64 [==============================] - 47s 727ms/step - loss: 0.3679 - acc: 0.8719 - val_loss: 0.4659 - val_acc: 0.8859\n",
      "Epoch 18/40\n",
      "64/64 [==============================] - 47s 735ms/step - loss: 0.3167 - acc: 0.8934 - val_loss: 0.5005 - val_acc: 0.8913\n",
      "Epoch 19/40\n",
      "64/64 [==============================] - 47s 739ms/step - loss: 0.3201 - acc: 0.8973 - val_loss: 0.3098 - val_acc: 0.9185\n",
      "Epoch 20/40\n",
      "64/64 [==============================] - 47s 727ms/step - loss: 0.2940 - acc: 0.8983 - val_loss: 0.2961 - val_acc: 0.9076\n",
      "Epoch 21/40\n",
      "64/64 [==============================] - 45s 709ms/step - loss: 0.3020 - acc: 0.9003 - val_loss: 0.3433 - val_acc: 0.9022\n",
      "Epoch 22/40\n",
      "64/64 [==============================] - 45s 705ms/step - loss: 0.3004 - acc: 0.8876 - val_loss: 0.4099 - val_acc: 0.8804\n",
      "Epoch 23/40\n",
      "64/64 [==============================] - 44s 688ms/step - loss: 0.4009 - acc: 0.8592 - val_loss: 0.3042 - val_acc: 0.8967\n",
      "Epoch 24/40\n",
      "64/64 [==============================] - 45s 707ms/step - loss: 0.2530 - acc: 0.9069 - val_loss: 0.3886 - val_acc: 0.9185\n",
      "Epoch 25/40\n",
      "64/64 [==============================] - 44s 689ms/step - loss: 0.2980 - acc: 0.8816 - val_loss: 0.2858 - val_acc: 0.9130\n",
      "Epoch 26/40\n",
      "64/64 [==============================] - 45s 706ms/step - loss: 0.2182 - acc: 0.9131 - val_loss: 0.4275 - val_acc: 0.9130\n",
      "Epoch 27/40\n",
      "64/64 [==============================] - 43s 667ms/step - loss: 0.2178 - acc: 0.9216 - val_loss: 0.2823 - val_acc: 0.9427\n",
      "Epoch 28/40\n",
      "64/64 [==============================] - 43s 665ms/step - loss: 0.2357 - acc: 0.9255 - val_loss: 0.3055 - val_acc: 0.9348\n",
      "Epoch 29/40\n",
      "64/64 [==============================] - 44s 694ms/step - loss: 0.1928 - acc: 0.9315 - val_loss: 0.1804 - val_acc: 0.9402\n",
      "Epoch 30/40\n",
      "64/64 [==============================] - 44s 687ms/step - loss: 0.1946 - acc: 0.9315 - val_loss: 0.3811 - val_acc: 0.9076\n",
      "Epoch 31/40\n",
      "64/64 [==============================] - 42s 661ms/step - loss: 0.1858 - acc: 0.9354 - val_loss: 0.4445 - val_acc: 0.9185\n",
      "Epoch 32/40\n",
      "64/64 [==============================] - 44s 686ms/step - loss: 0.1812 - acc: 0.9325 - val_loss: 0.1448 - val_acc: 0.9511\n",
      "Epoch 33/40\n",
      "64/64 [==============================] - 43s 668ms/step - loss: 0.2195 - acc: 0.9149 - val_loss: 0.3305 - val_acc: 0.9293\n",
      "Epoch 34/40\n",
      "64/64 [==============================] - 44s 685ms/step - loss: 0.1850 - acc: 0.9375 - val_loss: 0.4192 - val_acc: 0.9293\n",
      "Epoch 35/40\n",
      "64/64 [==============================] - 45s 704ms/step - loss: 0.1691 - acc: 0.9385 - val_loss: 0.4373 - val_acc: 0.9130\n",
      "Epoch 36/40\n",
      "64/64 [==============================] - 45s 706ms/step - loss: 0.2181 - acc: 0.9185 - val_loss: 0.3019 - val_acc: 0.9185\n",
      "Epoch 37/40\n",
      "64/64 [==============================] - 43s 669ms/step - loss: 0.1583 - acc: 0.9382 - val_loss: 0.3584 - val_acc: 0.9348\n",
      "Epoch 38/40\n",
      "64/64 [==============================] - 43s 665ms/step - loss: 0.1614 - acc: 0.9392 - val_loss: 0.4735 - val_acc: 0.9239\n",
      "Epoch 39/40\n",
      "64/64 [==============================] - 43s 673ms/step - loss: 0.1915 - acc: 0.9375 - val_loss: 0.3453 - val_acc: 0.9348\n",
      "Epoch 40/40\n",
      "64/64 [==============================] - 43s 674ms/step - loss: 0.1911 - acc: 0.9198 - val_loss: 0.2345 - val_acc: 0.9375\n"
     ]
    }
   ],
   "source": [
    "training_generator = trainingDataGenerator.flow_from_directory(\n",
    "    training_directory,\n",
    "    target_size=(image_width, image_height), # all images resized to 250 x 250\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical') # we need categorical labels for categorical_crossentropy loss\n",
    "\n",
    "validation_generator = validationDataGenerator.flow_from_directory(\n",
    "    validation_directory,\n",
    "    target_size=(image_width, image_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "classifier.fit_generator(\n",
    "    training_generator,\n",
    "    steps_per_epoch=number_training_imgs // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=number_validation_imgs // batch_size)\n",
    "\n",
    "classifier.save_weights('weights.h5') #save computed weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the fitted model and generating predicted labels + filenames to find out what got predicted for each testing image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = testDataGenerator.flow_from_directory(\n",
    "        testing_directory,\n",
    "        target_size=(250, 250),\n",
    "        color_mode=\"rgb\",\n",
    "        shuffle = False,\n",
    "        class_mode='categorical',\n",
    "        batch_size=1)\n",
    "\n",
    "filenames = test_generator.filenames #generate filenames\n",
    "number_of_samples = len(filenames)\n",
    "\n",
    "index=0\n",
    "\n",
    "image, label = test_generator._get_batches_of_transformed_samples(np.array([index]))\n",
    "image_name = test_generator.filenames[index]\n",
    "\n",
    "test_generator.reset()\n",
    "\n",
    "predict = classifier.predict_generator(test_generator,steps = number_of_samples)\n",
    "predicted_class_indices=np.argmax(predict,axis=1) # predicted_class_indices contains predicted labels(0,1,2,3)\n",
    "\n",
    "labels = (training_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_true = np.array([0] * 50 + [1] * 50 + [2] * 50 + [3] * 50) # since we have 50 test images belonging to each class\n",
    "y_pred = predicted_class_indices\n",
    "con_mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "norm_conf = []\n",
    "\n",
    "for i in con_mat:\n",
    "    a = 0\n",
    "    tmp_arr = []\n",
    "    a = sum(i, 0)\n",
    "    for j in i:\n",
    "        tmp_arr.append(float(j)/float(a))\n",
    "    norm_conf.append(tmp_arr)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.clf()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_aspect(1)\n",
    "res = ax.imshow(np.array(norm_conf), cmap=plt.cm.jet, \n",
    "                interpolation='nearest')\n",
    "\n",
    "width, height = con_mat.shape\n",
    "\n",
    "for x in xrange(width):\n",
    "    for y in xrange(height):\n",
    "        ax.annotate(str(con_mat[x][y]), xy=(y, x), \n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center')\n",
    "\n",
    "\n",
    "cb = fig.colorbar(res)\n",
    "\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title('Confusion matrix ')\n",
    "plt.xticks(np.arange(0,4), ['Beds', 'Cabinets', 'Chairs', 'Desks'])\n",
    "plt.yticks(np.arange(0,4), ['Beds', 'Cabinets', 'Chairs', 'Desks'])\n",
    "plt.savefig('confusion_matrix.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I output the predicted results for each image into a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results.to_csv(\"results.csv\",index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
